{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f33a4c-e8cd-4304-9e13-8e45c043c097",
   "metadata": {},
   "source": [
    "<h1><u>Capstone 2 - Coffee Shop - Modeling</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc6f579-a945-454f-8b02-7f0bd6cbe9d3",
   "metadata": {},
   "source": [
    "[Rubric](https://docs.google.com/document/d/1rbG66SRqRj73Y-KtI_0qlkMX2CSGrvWddvi1V-WYXcY/edit)\n",
    "\n",
    "In previous notebooks I have already defined my problem, cleaned the data set, created dummy variables for categorical data, standardized the originally numeric data, and created the train/test split. The data set is from Kaggle and can be found [here](https://www.kaggle.com/datasets/patkle/coffeereviewcom-over-7000-ratings-and-reviews). The previously completed data cleaning notebook can be found [here](https://github.com/lindseyc735/Springboard/blob/main/Capstone%202/Capstone_2_data_wrangling.ipynb). Please see the below review of the project prior to considering the modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f83ebe-fe44-4aad-9024-8361915efc3f",
   "metadata": {},
   "source": [
    "<u>**Problem Statement:**</u>\n",
    "<br>What features most affect the coffee rating?\n",
    "\n",
    "<u>**Context:**</u>\n",
    "<br>A start-up coffee company is creating their signature blend to sell alongside the more generic blends of coffee. The start-up needs to know what three features to primarily incorporate into their signature blend to maximize its popularity and distinguish their company from other coffee companies.\n",
    "\n",
    "<u>**Criteria for Success:**</u>\n",
    "<br>Determine the three coffee features that will create a popular, signature blend of coffee.\n",
    "\n",
    "<u>**Scope of Solution Space:**</u>\n",
    "<br>Rating\n",
    "<br>Acidity\n",
    "<br>Aftertaste\n",
    "<br>Aroma\n",
    "<br>Body\n",
    "<br>Flavor\n",
    "<br>Review description\n",
    "<br>Country of origin\n",
    "<br>Roast level\n",
    "<br>Roaster\n",
    "<br>Roaster location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5b1c10a-751d-4bc7-9ca7-7f49be3cac81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>aroma</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>coffee_origin_20% Kona; other blend components not disclosed</th>\n",
       "      <th>coffee_origin_40% Colombia; 40% Brazil; 20% Rwanda</th>\n",
       "      <th>coffee_origin_50% Colombia, 35% Ethiopia, 15% Sumatra</th>\n",
       "      <th>coffee_origin_50% Colombia; 50% Ethiopia</th>\n",
       "      <th>coffee_origin_50% Yirgacheffe Ethiopia; 25% Papua New Guinea; 25% Brazil</th>\n",
       "      <th>coffee_origin_A blend of coffees from southern India</th>\n",
       "      <th>...</th>\n",
       "      <th>roaster_location_Youngstown, Ohio</th>\n",
       "      <th>roaster_location_Yuanlin, Taiwan</th>\n",
       "      <th>roaster_location_Yun-Lin County, Taiwan</th>\n",
       "      <th>roaster_location_Zhongli, Taiwan</th>\n",
       "      <th>roaster_location_Zhubei City, Taiwan</th>\n",
       "      <th>roaster_location_Zhubei, Taiwan</th>\n",
       "      <th>roaster_location_Zhuwei, Taiwan</th>\n",
       "      <th>roaster_location_Zimbabwe</th>\n",
       "      <th>roaster_location_Zurich, Switzerland</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040738</td>\n",
       "      <td>0.700223</td>\n",
       "      <td>-0.111574</td>\n",
       "      <td>0.554627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.517301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040738</td>\n",
       "      <td>0.700223</td>\n",
       "      <td>-0.111574</td>\n",
       "      <td>0.554627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040738</td>\n",
       "      <td>0.700223</td>\n",
       "      <td>1.057494</td>\n",
       "      <td>0.554627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040738</td>\n",
       "      <td>0.700223</td>\n",
       "      <td>1.057494</td>\n",
       "      <td>0.554627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040738</td>\n",
       "      <td>0.700223</td>\n",
       "      <td>-0.111574</td>\n",
       "      <td>0.554627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.517301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aftertaste     aroma      body    flavor  \\\n",
       "0    0.040738  0.700223 -0.111574  0.554627   \n",
       "1    0.040738  0.700223 -0.111574  0.554627   \n",
       "2    0.040738  0.700223  1.057494  0.554627   \n",
       "3    0.040738  0.700223  1.057494  0.554627   \n",
       "4    0.040738  0.700223 -0.111574  0.554627   \n",
       "\n",
       "   coffee_origin_20% Kona; other blend components not disclosed  \\\n",
       "0                                                  0              \n",
       "1                                                  0              \n",
       "2                                                  0              \n",
       "3                                                  0              \n",
       "4                                                  0              \n",
       "\n",
       "   coffee_origin_40% Colombia; 40% Brazil; 20% Rwanda  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "3                                                  0    \n",
       "4                                                  0    \n",
       "\n",
       "   coffee_origin_50% Colombia, 35% Ethiopia, 15% Sumatra  \\\n",
       "0                                                  0       \n",
       "1                                                  0       \n",
       "2                                                  0       \n",
       "3                                                  0       \n",
       "4                                                  0       \n",
       "\n",
       "   coffee_origin_50% Colombia; 50% Ethiopia  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   coffee_origin_50% Yirgacheffe Ethiopia; 25% Papua New Guinea; 25% Brazil  \\\n",
       "0                                                  0                          \n",
       "1                                                  0                          \n",
       "2                                                  0                          \n",
       "3                                                  0                          \n",
       "4                                                  0                          \n",
       "\n",
       "   coffee_origin_A blend of coffees from southern India  ...  \\\n",
       "0                                                  0     ...   \n",
       "1                                                  0     ...   \n",
       "2                                                  0     ...   \n",
       "3                                                  0     ...   \n",
       "4                                                  0     ...   \n",
       "\n",
       "   roaster_location_Youngstown, Ohio  roaster_location_Yuanlin, Taiwan  \\\n",
       "0                                  0                                 0   \n",
       "1                                  0                                 0   \n",
       "2                                  0                                 0   \n",
       "3                                  0                                 0   \n",
       "4                                  0                                 0   \n",
       "\n",
       "   roaster_location_Yun-Lin County, Taiwan  roaster_location_Zhongli, Taiwan  \\\n",
       "0                                        0                                 0   \n",
       "1                                        0                                 0   \n",
       "2                                        0                                 0   \n",
       "3                                        0                                 0   \n",
       "4                                        0                                 0   \n",
       "\n",
       "   roaster_location_Zhubei City, Taiwan  roaster_location_Zhubei, Taiwan  \\\n",
       "0                                     0                                0   \n",
       "1                                     0                                0   \n",
       "2                                     0                                0   \n",
       "3                                     0                                0   \n",
       "4                                     0                                0   \n",
       "\n",
       "   roaster_location_Zhuwei, Taiwan  roaster_location_Zimbabwe  \\\n",
       "0                                0                          0   \n",
       "1                                0                          0   \n",
       "2                                0                          0   \n",
       "3                                0                          0   \n",
       "4                                0                          0   \n",
       "\n",
       "   roaster_location_Zurich, Switzerland    rating  \n",
       "0                                     0  0.517301  \n",
       "1                                     0  0.274650  \n",
       "2                                     0  0.759951  \n",
       "3                                     0  0.759951  \n",
       "4                                     0  0.517301  \n",
       "\n",
       "[5 rows x 4174 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Removes deprecation warnings\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns # For all our visualization needs.\n",
    "from pandas_profiling import ProfileReport # Creates data description, visuals, and missing value statistics for the data frame\n",
    "from IPython.display import display\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import Modeling Tools\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Import Metric Tools for Evaluating Models\n",
    "from sklearn.metrics import mean_squared_error #MSE\n",
    "from sklearn.metrics import mean_absolute_error #MAE\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Import the data and run a ProfileReport to find statistical descriptions, visuals, and missing value information\n",
    "df = pd.read_csv('reordered_preprocessed_coffee4.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801151c1-1eda-4d36-976e-05a48cafa203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train/test split data\n",
    "X = df.iloc[:, :-1]  # Features (all columns except the last one)\n",
    "y = df.iloc[:, -1]   # Target (last column)\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50fe0a82-3fc8-4457-b4d1-fe415ce91290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7037, 4174)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b755f08-b637-4afb-81bf-a46cc0343948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5629, 4173), (5629, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519a2262-0f67-4342-aae3-d1d492f34a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1408, 4173), (1408, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fe920c-370f-4575-8146-7e83cfb10b2b",
   "metadata": {},
   "source": [
    "# <u>Modeling</u>  \n",
    "Goal: Build 3 to 5 different models and identify the best one.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4aef4c-3fb0-44eb-bc73-f96b5760be4e",
   "metadata": {},
   "source": [
    "# Fit models with a training dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99af5a7-ef5a-42e2-8012-c44e5230d338",
   "metadata": {},
   "source": [
    "# Model 1: Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2f2998b-3068-4d01-a007-221419786e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model specific variables for the train/test set components\n",
    "XLR = X\n",
    "yLR = y\n",
    "X_trainLR = X_train\n",
    "X_testLR = X_test\n",
    "y_trainLR = y_train\n",
    "y_testLR = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084cb980-04a8-4746-8f56-5c39c1300b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, fit the model on the data, and make predictions\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_trainLR, y_trainLR)\n",
    "y_predLR = lr.predict(X_testLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74179d00-b256-4b67-8390-ef03b18fa966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for the Linear Regression Model: 446544337.98906857\n",
      "Mean Squared Error for the Linear Regression Model: 9.467784905330545e+19\n",
      "RMSE for the Linear Regression Model:  9730254315.962427\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using MAE, MSE, and RMSE\n",
    "maeLR = mean_absolute_error(y_testLR, y_predLR)\n",
    "mseLR = mean_squared_error(y_testLR, y_predLR)\n",
    "rmseLR = np.sqrt(mseLR)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Absolute Error for the Linear Regression Model: {maeLR}\")\n",
    "print(f\"Mean Squared Error for the Linear Regression Model: {mseLR}\")\n",
    "print(f\"RMSE for the Linear Regression Model: \", rmseLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d354154-afa2-4671-bb87-9320463bd80e",
   "metadata": {},
   "source": [
    "# Linear Regression with GridSearchCV() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51598a75-cdc5-4917-acd6-7a35f2cae401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearRegression(),\n",
       "             param_grid={'normalize': [True, False]},\n",
       "             refit='neg_mean_squared_error',\n",
       "             scoring={'neg_mean_absolute_error': make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "                      'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False),\n",
       "                      'neg_root_mean_squared_error': make_scorer(<lambda>, greater_is_better=False)})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model specific variables for the train/test set components\n",
    "XLR_gridsearchcv = X\n",
    "yLR_gridsearchcv = y\n",
    "X_trainLR_gridsearchcv = X_train\n",
    "X_testLR_gridsearchcv = X_test\n",
    "y_trainLR_gridsearchcv = y_train\n",
    "y_testLR_gridsearchcv = y_test\n",
    "\n",
    "# Define the parameter grid for linear regression\n",
    "parametersLR_gridsearchcv = {'normalize': [True, False]}\n",
    "\n",
    "# Define custom scoring functions for MAE, MSE, and RMSE\n",
    "scoringLR_gridsearchcv = {\n",
    "    'neg_mean_absolute_error': make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False),\n",
    "    'neg_root_mean_squared_error': make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)), greater_is_better=False)\n",
    "}\n",
    "    \n",
    "# Still use 'lr' for the regression model\n",
    "    \n",
    "# Create GridSearchCV instance with multiple scoring metrics\n",
    "grid_searchLR = GridSearchCV(lr, parametersLR_gridsearchcv, scoring=scoringLR_gridsearchcv, refit = 'neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Fit the model\n",
    "grid_searchLR.fit(X_trainLR_gridsearchcv, y_trainLR_gridsearchcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4778c03f-74fc-46f6-88ea-727381c24890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Linear Regression with GridSearchCV: {'normalize': False}\n",
      "Best Estimator for Linear Regression with GridSearchCV: LinearRegression(normalize=False)\n",
      "Mean Absolute Error for the LRG: 446544337.98906857\n",
      "Mean Squared Error for the LRG: 9.467784905330545e+19\n",
      "RMSE for the LRG:  9730254315.962427\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters and best estimator\n",
    "best_paramsLR = grid_searchLR.best_params_\n",
    "best_estimatorLR = grid_searchLR.best_estimator_\n",
    "print(\"Best Parameters for Linear Regression with GridSearchCV:\", best_paramsLR)\n",
    "print(\"Best Estimator for Linear Regression with GridSearchCV:\", best_estimatorLR)\n",
    "\n",
    "# Make a prediction on the best estimator and evaluate the model using all three metrics\n",
    "y_predLR_gridsearchcv = best_estimatorLR.predict(X_testLR_gridsearchcv)\n",
    "maeLR_gridsearchcv = mean_absolute_error(y_testLR_gridsearchcv, y_predLR_gridsearchcv)\n",
    "mseLR_gridsearchcv = mean_squared_error(y_testLR_gridsearchcv, y_predLR_gridsearchcv)\n",
    "rmseLR_gridsearchcv = np.sqrt(mseLR_gridsearchcv)\n",
    "\n",
    "# Print the MAE, MSE, and RMSE\n",
    "print(f\"Mean Absolute Error for the LRG: {maeLR_gridsearchcv}\")\n",
    "print(f\"Mean Squared Error for the LRG: {mseLR_gridsearchcv}\")\n",
    "print(f\"RMSE for the LRG: \", rmseLR_gridsearchcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2e97e-8877-47af-9478-2d60ad24b9df",
   "metadata": {},
   "source": [
    "# Model 2: Random Forest Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd2a6b63-ec2c-41f8-83b8-5209a5efd570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model specific variables for the train/test set components\n",
    "XRF = X\n",
    "yRF = y\n",
    "X_trainRF = X_train\n",
    "X_testRF = X_test\n",
    "y_trainRF = y_train\n",
    "y_testRF = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f805a69d-106d-464a-9fce-ee12de786bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf.fit(X_trainRF, y_trainRF.values.ravel())  # Using .values.ravel() to convert y_train DataFrame to a 1D array\n",
    "\n",
    "# Predict on the test data\n",
    "y_predRF = rf.predict(X_testRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8e0d68d-d04f-417b-ae34-af8364e2adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for the Random Forest Model: 0.1794049411585514\n",
      "Mean Squared Error for the Random Forest Regressor Model: 0.0832775065420507\n",
      "RMSE for the Random Forest Regressor Model:  0.28857842355597324\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAE\n",
    "maeRF= mean_absolute_error(y_testRF, y_predRF)\n",
    "\n",
    "# Print the MAE\n",
    "print(f\"Mean Absolute Error for the Random Forest Model: {maeRF}\")\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for evaluation\n",
    "mseRF = mean_squared_error(y_testRF, y_predRF)\n",
    "print(f\"Mean Squared Error for the Random Forest Regressor Model: {mseRF}\")\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmseRF = np.sqrt(mseRF)\n",
    "print(f\"RMSE for the Random Forest Regressor Model: \", rmseRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9336a9cc-4c11-422c-be01-f6e81f1fc55d",
   "metadata": {},
   "source": [
    "# Random Forest Regressor with GridSearchCV #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52f91d76-5ae9-42ea-9e63-d78d6ca03881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "paramsRF = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_searchRF = GridSearchCV(rf, paramsRF, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_searchRF.fit(X_trainRF, y_trainRF.values.ravel())\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_paramsRF = grid_searchRF.best_params_\n",
    "best_estimatorRF = grid_searchRF.best_estimator_\n",
    "\n",
    "# Make predictions using the best estimator\n",
    "y_predRF_best = best_estimatorRF.predict(X_testRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52408bde-487d-4161-ab5e-65f5264aed36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest with GridSearchCV: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Best Estimator for Random Forest with GridSearchCV: RandomForestRegressor(max_depth=20, n_estimators=150, random_state=42)\n",
      "Mean Absolute Error for Random Forest with GridSearchCV: 0.18457171428242514\n",
      "Mean Squared Error for Random Forest with GridSearchCV: 0.08239772155392212\n",
      "RMSE for Random Forest with GridSearchCV:  0.28705003318920225\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Absolute Error for the best model\n",
    "mae_bestRF = mean_absolute_error(y_testRF, y_predRF_best)\n",
    "\n",
    "# Print the best parameters and best estimator\n",
    "print(\"Best Parameters for Random Forest with GridSearchCV:\", best_paramsRF)\n",
    "print(\"Best Estimator for Random Forest with GridSearchCV:\", best_estimatorRF)\n",
    "\n",
    "# Evaluate the model using all three metrics\n",
    "maeRF_gridsearchcv = mean_absolute_error(y_testRF, y_predRF_best)\n",
    "mseRF_gridsearchcv = mean_squared_error(y_testRF, y_predRF_best)\n",
    "rmseRF_gridsearchcv = np.sqrt(mseRF_gridsearchcv)\n",
    "\n",
    "# Print the MAE, MSE, and RMSE\n",
    "print(f\"Mean Absolute Error for Random Forest with GridSearchCV: {maeRF_gridsearchcv}\")\n",
    "print(f\"Mean Squared Error for Random Forest with GridSearchCV: {mseRF_gridsearchcv}\")\n",
    "print(f\"RMSE for Random Forest with GridSearchCV: \", rmseRF_gridsearchcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf05fd6e-caa9-45bb-86aa-9ea8f03403b9",
   "metadata": {},
   "source": [
    "# Model 3: Gradient Boosting Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1207e8a-88d1-4ea6-b134-35ff65014156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model specific variables for the train/test set components\n",
    "XGB = X\n",
    "yGB = y\n",
    "X_trainGB = X_train\n",
    "X_testGB = X_test\n",
    "y_trainGB = y_train\n",
    "y_testGB = y_test\n",
    "\n",
    "# Install XGBoost\n",
    "#! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2af790e5-77cb-4307-b9f1-845a48f6a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "gb = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=10, seed=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gb.fit(X_trainGB, y_trainGB)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predGB = gb.predict(X_testGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7330c2d6-457b-435e-b039-e9f9bfa7d325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for the Extreme Gradient Boosting Model: 0.19203128125179927\n",
      "Mean Squared Error for the Extreme Gradient Boosting Model: 0.08294503229995759\n",
      "RMSE for the Extreme Gradient Boosting Model:  0.2880017921818501\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAE\n",
    "maeGB = mean_absolute_error(y_testGB, y_predGB)\n",
    "\n",
    "# Print the MAE\n",
    "print(f\"Mean Absolute Error for the Extreme Gradient Boosting Model: {maeGB}\")\n",
    "\n",
    "# Calculate Mean Squared Error for evaluation\n",
    "mseGB = mean_squared_error(y_testGB, y_predGB)\n",
    "print(f\"Mean Squared Error for the Extreme Gradient Boosting Model: {mseGB}\")\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmseGB = np.sqrt(mseGB)\n",
    "print(f\"RMSE for the Extreme Gradient Boosting Model: \", rmseGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec26a9-96df-4467-b836-07063244a89e",
   "metadata": {},
   "source": [
    "# Gradient Boosting with GridSearchCV #Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0a68a55-3a37-4442-9bef-2bf6714010bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_gridGB = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "gb = xgb.XGBRegressor(objective='reg:squarederror', seed=42)\n",
    "\n",
    "# Initialize GridSearchCV with scoring='neg_mean_squared_error' to minimize MSE\n",
    "grid_searchGB = GridSearchCV(gb, param_gridGB, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_searchGB.fit(X_trainGB, y_trainGB)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_paramsGB = grid_searchGB.best_params_\n",
    "best_estimatorGB = grid_searchGB.best_estimator_\n",
    "\n",
    "# Make predictions using the best estimator\n",
    "y_predGB_best = best_estimatorGB.predict(X_testGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab87235c-1c1f-4806-8ad9-2a0949d98d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Extreme Gradient Boosting with GridSearchCV: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}\n",
      "Best Estimator for Extreme Gradient Boosting with GridSearchCV: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=50, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "Mean Absolute Error for Extreme Gradient Boosting with GridSearchCV: 0.18457988501016312\n",
      "Mean Squared Error for Extreme Gradient Boosting with GridSearchCV: 0.08032732548700275\n",
      "RMSE for Extreme Gradient Boosting with GridSearchCV:  0.2834207569797998\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters and best estimator\n",
    "print(\"Best Parameters for Extreme Gradient Boosting with GridSearchCV:\", best_paramsGB)\n",
    "print(\"Best Estimator for Extreme Gradient Boosting with GridSearchCV:\", best_estimatorGB)\n",
    "\n",
    "# Evaluate the model using all three metrics\n",
    "maeGB_gridsearchcv = mean_absolute_error(y_testGB, y_predGB_best)\n",
    "mseGB_gridsearchcv = mean_squared_error(y_testGB, y_predGB_best)\n",
    "rmseGB_gridsearchcv = np.sqrt(mseGB_gridsearchcv)\n",
    "\n",
    "# Print the MAE, MSE, and RMSE\n",
    "print(f\"Mean Absolute Error for Extreme Gradient Boosting with GridSearchCV: {maeGB_gridsearchcv}\")\n",
    "print(f\"Mean Squared Error for Extreme Gradient Boosting with GridSearchCV: {mseGB_gridsearchcv}\")\n",
    "print(f\"RMSE for Extreme Gradient Boosting with GridSearchCV: \", rmseGB_gridsearchcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c28bc-d11f-47d7-8f35-c87b5ae4ae5d",
   "metadata": {},
   "source": [
    "# Model 4: Support Vector Regression (SVR) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd80328b-9a97-4a58-b2a3-60320d424b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model specific variables for the train/test set components\n",
    "XSVR = X\n",
    "ySVR = y\n",
    "X_trainSVR = X_train\n",
    "X_testSVR = X_test\n",
    "y_trainSVR = y_train\n",
    "y_testSVR = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4eff8084-7824-43da-a0c3-efb10c760dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Initialize the SVR model\n",
    "svr = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "svr.fit(X_trainSVR, y_trainSVR)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predSVR = svr.predict(X_testSVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16cc5632-b49d-4cda-aac9-bc0e2d95eeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for the Support Vector Regression Model: 0.18286007431960155\n",
      "Mean Squared Error for the Support Vector Regression Model: 0.08128681850700242\n",
      "RMSE for the Support Vecgtor Regression Model:  0.28510843289352633\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAE\n",
    "maeSVR= mean_absolute_error(y_testSVR, y_predSVR)\n",
    "\n",
    "# Print the MAE\n",
    "print(f\"Mean Absolute Error for the Support Vector Regression Model: {maeSVR}\")\n",
    "\n",
    "# Calculate Mean Squared Error for evaluation\n",
    "mseSVR = mean_squared_error(y_testSVR, y_predSVR)\n",
    "print(f\"Mean Squared Error for the Support Vector Regression Model: {mseSVR}\")\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmseSVR = np.sqrt(mseSVR)\n",
    "print(f\"RMSE for the Support Vecgtor Regression Model: \", rmseSVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe3bdf2-2642-4ab6-9511-d9b77d167ce8",
   "metadata": {},
   "source": [
    "# Support Vector Regression (SVR) with GridSearchCV #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5f43ca5-e287-43a0-9f8c-e8cd67d0ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_gridSVR = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'epsilon': [0.01, 0.1, 0.2],\n",
    "    'kernel': ['linear', 'poly', 'rbf']\n",
    "}\n",
    "\n",
    "# Initialize the SVR model\n",
    "svr = SVR()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_searchSVR = GridSearchCV(svr, param_gridSVR, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_searchSVR.fit(X_trainSVR, y_trainSVR.values.ravel())\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_paramsSVR = grid_searchSVR.best_params_\n",
    "best_estimatorSVR = grid_searchSVR.best_estimator_\n",
    "\n",
    "# Make predictions using the best estimator\n",
    "y_predSVR_best = best_estimatorSVR.predict(X_testSVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7de11590-24c4-4623-bb2b-e1985b3f74cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Support Vector Regression with GridSearchCV: {'C': 0.1, 'epsilon': 0.2, 'kernel': 'linear'}\n",
      "Best Estimator for Support Vector Regression with GridSearchCV: SVR(C=0.1, epsilon=0.2, kernel='linear')\n",
      "Mean Absolute Error for Support Vector Regression with GridSearchCV: 0.19640981425061413\n",
      "Mean Squared Error for Support Vector Regression with GridSearchCV: 0.08474750686718774\n",
      "RMSE for Support Vector Regression with GridSearchCV:  0.2911142505395223\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters and best estimator\n",
    "print(\"Best Parameters for Support Vector Regression with GridSearchCV:\", best_paramsSVR)\n",
    "print(\"Best Estimator for Support Vector Regression with GridSearchCV:\", best_estimatorSVR)\n",
    "\n",
    "# Evaluate the model using all three metrics\n",
    "maeSVR_gridsearchcv = mean_absolute_error(y_testSVR, y_predSVR_best)\n",
    "mseSVR_gridsearchcv = mean_squared_error(y_testSVR, y_predSVR_best)\n",
    "rmseSVR_gridsearchcv = np.sqrt(mseSVR_gridsearchcv)\n",
    "\n",
    "# Print the MAE, MSE, and RMSE\n",
    "print(f\"Mean Absolute Error for Support Vector Regression with GridSearchCV: {maeSVR_gridsearchcv}\")\n",
    "print(f\"Mean Squared Error for Support Vector Regression with GridSearchCV: {mseSVR_gridsearchcv}\")\n",
    "print(f\"RMSE for Support Vector Regression with GridSearchCV: \", rmseSVR_gridsearchcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ecda51-2829-4244-82bf-257d3cbde48f",
   "metadata": {},
   "source": [
    "# Model 5: Elastic Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c4e4a69-0381-4807-bc61-cde907627eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model specific variables for the train/test set components\n",
    "XEN = X\n",
    "yEN = y\n",
    "X_trainEN = X_train\n",
    "X_testEN = X_test\n",
    "y_trainEN = y_train\n",
    "y_testEN = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3882d481-a37c-4ea5-b8bd-9d24436cfc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Initialize the Elastic Net model\n",
    "en = ElasticNet(alpha=1.0, l1_ratio=0.5)  \n",
    "\n",
    "# Fit the model on the training data\n",
    "en.fit(X_trainEN, y_trainEN)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predEN = en.predict(X_testEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46e31f8c-f242-407e-b0e6-cffb3d8f3636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for the Elastic Net Model: 0.4807004765238523\n",
      "Mean Squared Error for the Elastic Net Model: 0.4763833374938104\n",
      "RMSE for the Elastic Net Model:  0.6902052864864268\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAE\n",
    "maeEN = mean_absolute_error(y_testEN, y_predEN)\n",
    "\n",
    "# Print the MAE\n",
    "print(f\"Mean Absolute Error for the Elastic Net Model: {maeEN}\")\n",
    "\n",
    "# Calculate Mean Squared Error for evaluation\n",
    "mseEN = mean_squared_error(y_testEN, y_predEN)\n",
    "print(f\"Mean Squared Error for the Elastic Net Model: {mseEN}\")\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmseEN = np.sqrt(mseEN)\n",
    "print(f\"RMSE for the Elastic Net Model: \", rmseEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3484f0eb-2354-4a99-9360-4985ed20875a",
   "metadata": {},
   "source": [
    "# Elastic Net with GridSearchCV #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52fe78e8-24bf-45a9-aa44-0097eefbb653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_gridEN = {\n",
    "    'alpha': [0.01, 0.1, 1.0],\n",
    "    'l1_ratio': [0.1, 0.5, 0.9]\n",
    "}\n",
    "\n",
    "# Initialize the Elastic Net model\n",
    "en = ElasticNet()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_searchEN = GridSearchCV(en, param_gridEN, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_searchEN.fit(X_trainEN, y_trainEN)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_paramsEN = grid_searchEN.best_params_\n",
    "best_estimatorEN = grid_searchEN.best_estimator_\n",
    "\n",
    "# Make predictions using the best estimator\n",
    "y_predEN_best = best_estimatorEN.predict(X_testEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d3a48d8-d6a1-46b2-99e0-952583af8430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Elastic Net with GridSearchCV: {'alpha': 0.01, 'l1_ratio': 0.1}\n",
      "Best Estimator for Elastic Net with GridSearchCV: ElasticNet(alpha=0.01, l1_ratio=0.1)\n",
      "Mean Absolute Error for Support Vector Regression with GridSearchCV: 0.2003814539543021\n",
      "Mean Squared Error for Support Vector Regression with GridSearchCV: 0.09039427542149797\n",
      "RMSE for Support Vector Regression with GridSearchCV:  0.30065640758430207\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters and best estimator\n",
    "print(\"Best Parameters for Elastic Net with GridSearchCV:\", best_paramsEN)\n",
    "print(\"Best Estimator for Elastic Net with GridSearchCV:\", best_estimatorEN)\n",
    "\n",
    "# Evaluate the model using all three metrics\n",
    "maeEN_gridsearchcv = mean_absolute_error(y_testEN, y_predEN_best)\n",
    "mseEN_gridsearchcv = mean_squared_error(y_testEN, y_predEN_best)\n",
    "rmseEN_gridsearchcv = np.sqrt(mseEN_gridsearchcv)\n",
    "\n",
    "# Print the MAE, MSE, and RMSE\n",
    "print(f\"Mean Absolute Error for Support Vector Regression with GridSearchCV: {maeEN_gridsearchcv}\")\n",
    "print(f\"Mean Squared Error for Support Vector Regression with GridSearchCV: {mseEN_gridsearchcv}\")\n",
    "print(f\"RMSE for Support Vector Regression with GridSearchCV: \", rmseEN_gridsearchcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be0ac4d-04ef-40fa-b856-b4ef44814367",
   "metadata": {},
   "source": [
    "# Review model outcomes â€” Iterate over additional models as needed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8c97ad7-919c-4345-8521-2f103c9ec992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model           MAE           MSE          RMSE\n",
      "0  Linear Regression  4.465443e+08  9.467785e+19  9.730254e+09\n",
      "1      Random Forest  1.794049e-01  8.327751e-02  2.885784e-01\n",
      "2         XGBoosting  1.920313e-01  8.294503e-02  2.880018e-01\n",
      "3                SVR  1.828601e-01  8.128682e-02  2.851084e-01\n",
      "4        Elastic Net  4.807005e-01  4.763833e-01  6.902053e-01\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary containing your data\n",
    "table = {\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'XGBoosting', 'SVR', 'Elastic Net'],\n",
    "    'MAE': [maeLR, maeRF, maeGB, maeSVR, maeEN], \n",
    "    'MSE': [mseLR, mseRF, mseGB, mseSVR, mseEN],\n",
    "    'RMSE': [rmseLR, rmseRF, rmseGB, rmseSVR, rmseEN]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "data_table = pd.DataFrame(table)\n",
    "\n",
    "# Display the data table\n",
    "print(data_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05f82ab0-ac0c-4ccd-b7ee-aad669dee56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model with GridSearchCV           MAE           MSE          RMSE\n",
      "0       Linear Regression  4.465443e+08  9.467785e+19  9.730254e+09\n",
      "1           Random Forest  1.845717e-01  8.239772e-02  2.870500e-01\n",
      "2              XGBoosting  1.845799e-01  8.032733e-02  2.834208e-01\n",
      "3                     SVR  1.964098e-01  8.474751e-02  2.911143e-01\n",
      "4             Elastic Net  2.003815e-01  9.039428e-02  3.006564e-01\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary containing your data\n",
    "table_gridsearchcv = {\n",
    "    'Model with GridSearchCV': ['Linear Regression', 'Random Forest', 'XGBoosting', 'SVR', 'Elastic Net'],\n",
    "    'MAE': [maeLR_gridsearchcv, maeRF_gridsearchcv, maeGB_gridsearchcv, maeSVR_gridsearchcv, maeEN_gridsearchcv], \n",
    "    'MSE': [mseLR_gridsearchcv, mseRF_gridsearchcv, mseGB_gridsearchcv, mseSVR_gridsearchcv, mseEN_gridsearchcv],\n",
    "    'RMSE': [rmseLR_gridsearchcv, rmseRF_gridsearchcv, rmseGB_gridsearchcv, rmseSVR_gridsearchcv, rmseEN_gridsearchcv]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "data_table_gridsearchcv = pd.DataFrame(table_gridsearchcv)\n",
    "\n",
    "# Display the data table\n",
    "print(data_table_gridsearchcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed66204-b741-4651-9db2-bb16da598720",
   "metadata": {},
   "source": [
    "# Identify the final model that you think is the best model for this project  \n",
    "Hint: the most powerful model isnâ€™t always the best one to use. Other considerations\n",
    "include computational complexity, scalability, and maintenance costs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3efb75-e872-42bc-a325-85c55702fa7d",
   "metadata": {},
   "source": [
    "In modeling both with and without GridSearchCV, Extreme Gradient Boosting displays the lowest MSE and RMSE, and second lowest MAE. I will select the Extreme Gradient Boosting as the best model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
