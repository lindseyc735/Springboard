{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f33a4c-e8cd-4304-9e13-8e45c043c097",
   "metadata": {},
   "source": [
    "<h1><u>Capstone 2 - Coffee Shop - Modeling</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc6f579-a945-454f-8b02-7f0bd6cbe9d3",
   "metadata": {},
   "source": [
    "[Rubric](https://docs.google.com/document/d/1rbG66SRqRj73Y-KtI_0qlkMX2CSGrvWddvi1V-WYXcY/edit)\n",
    "\n",
    "In previous notebooks I have already defined my problem, cleaned the data set, created dummy variables for categorical data, standardized the originally numeric data, and created the train/test split. The data set is from Kaggle and can be found [here](https://www.kaggle.com/datasets/patkle/coffeereviewcom-over-7000-ratings-and-reviews). The previously completed data cleaning notebook can be found [here](https://github.com/lindseyc735/Springboard/blob/main/Capstone%202/Capstone_2_data_wrangling.ipynb). Please see the below review of the project prior to considering the modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f83ebe-fe44-4aad-9024-8361915efc3f",
   "metadata": {},
   "source": [
    "<u>**Problem Statement:**</u>\n",
    "<br>What features most affect the coffee rating?\n",
    "\n",
    "<u>**Context:**</u>\n",
    "<br>A start-up coffee company is creating their signature blend to sell alongside the more generic blends of coffee. The start-up needs to know what three features to primarily incorporate into their signature blend to maximize its popularity and distinguish their company from other coffee companies.\n",
    "\n",
    "<u>**Criteria for Success:**</u>\n",
    "<br>Determine the three coffee features that will create a popular, signature blend of coffee.\n",
    "\n",
    "<u>**Scope of Solution Space:**</u>\n",
    "<br>Rating\n",
    "<br>Acidity\n",
    "<br>Aftertaste\n",
    "<br>Aroma\n",
    "<br>Body\n",
    "<br>Flavor\n",
    "<br>Review description\n",
    "<br>Country of origin\n",
    "<br>Roast level\n",
    "<br>Roaster\n",
    "<br>Roaster location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b1c10a-751d-4bc7-9ca7-7f49be3cac81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>aroma</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>coffee_origin_20% Kona; other blend components not disclosed</th>\n",
       "      <th>coffee_origin_40% Colombia; 40% Brazil; 20% Rwanda</th>\n",
       "      <th>coffee_origin_50% Colombia, 35% Ethiopia, 15% Sumatra</th>\n",
       "      <th>coffee_origin_50% Colombia; 50% Ethiopia</th>\n",
       "      <th>coffee_origin_50% Yirgacheffe Ethiopia; 25% Papua New Guinea; 25% Brazil</th>\n",
       "      <th>coffee_origin_A blend of coffees from southern India</th>\n",
       "      <th>...</th>\n",
       "      <th>roaster_location_Youngstown, Ohio</th>\n",
       "      <th>roaster_location_Yuanlin, Taiwan</th>\n",
       "      <th>roaster_location_Yun-Lin County, Taiwan</th>\n",
       "      <th>roaster_location_Zhongli, Taiwan</th>\n",
       "      <th>roaster_location_Zhubei City, Taiwan</th>\n",
       "      <th>roaster_location_Zhubei, Taiwan</th>\n",
       "      <th>roaster_location_Zhuwei, Taiwan</th>\n",
       "      <th>roaster_location_Zimbabwe</th>\n",
       "      <th>roaster_location_Zurich, Switzerland</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040738</td>\n",
       "      <td>0.700223</td>\n",
       "      <td>-0.111574</td>\n",
       "      <td>0.554627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.517301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040738</td>\n",
       "      <td>0.700223</td>\n",
       "      <td>-0.111574</td>\n",
       "      <td>0.554627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040738</td>\n",
       "      <td>0.700223</td>\n",
       "      <td>1.057494</td>\n",
       "      <td>0.554627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040738</td>\n",
       "      <td>0.700223</td>\n",
       "      <td>1.057494</td>\n",
       "      <td>0.554627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040738</td>\n",
       "      <td>0.700223</td>\n",
       "      <td>-0.111574</td>\n",
       "      <td>0.554627</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.517301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aftertaste     aroma      body    flavor  \\\n",
       "0    0.040738  0.700223 -0.111574  0.554627   \n",
       "1    0.040738  0.700223 -0.111574  0.554627   \n",
       "2    0.040738  0.700223  1.057494  0.554627   \n",
       "3    0.040738  0.700223  1.057494  0.554627   \n",
       "4    0.040738  0.700223 -0.111574  0.554627   \n",
       "\n",
       "   coffee_origin_20% Kona; other blend components not disclosed  \\\n",
       "0                                                  0              \n",
       "1                                                  0              \n",
       "2                                                  0              \n",
       "3                                                  0              \n",
       "4                                                  0              \n",
       "\n",
       "   coffee_origin_40% Colombia; 40% Brazil; 20% Rwanda  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "3                                                  0    \n",
       "4                                                  0    \n",
       "\n",
       "   coffee_origin_50% Colombia, 35% Ethiopia, 15% Sumatra  \\\n",
       "0                                                  0       \n",
       "1                                                  0       \n",
       "2                                                  0       \n",
       "3                                                  0       \n",
       "4                                                  0       \n",
       "\n",
       "   coffee_origin_50% Colombia; 50% Ethiopia  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   coffee_origin_50% Yirgacheffe Ethiopia; 25% Papua New Guinea; 25% Brazil  \\\n",
       "0                                                  0                          \n",
       "1                                                  0                          \n",
       "2                                                  0                          \n",
       "3                                                  0                          \n",
       "4                                                  0                          \n",
       "\n",
       "   coffee_origin_A blend of coffees from southern India  ...  \\\n",
       "0                                                  0     ...   \n",
       "1                                                  0     ...   \n",
       "2                                                  0     ...   \n",
       "3                                                  0     ...   \n",
       "4                                                  0     ...   \n",
       "\n",
       "   roaster_location_Youngstown, Ohio  roaster_location_Yuanlin, Taiwan  \\\n",
       "0                                  0                                 0   \n",
       "1                                  0                                 0   \n",
       "2                                  0                                 0   \n",
       "3                                  0                                 0   \n",
       "4                                  0                                 0   \n",
       "\n",
       "   roaster_location_Yun-Lin County, Taiwan  roaster_location_Zhongli, Taiwan  \\\n",
       "0                                        0                                 0   \n",
       "1                                        0                                 0   \n",
       "2                                        0                                 0   \n",
       "3                                        0                                 0   \n",
       "4                                        0                                 0   \n",
       "\n",
       "   roaster_location_Zhubei City, Taiwan  roaster_location_Zhubei, Taiwan  \\\n",
       "0                                     0                                0   \n",
       "1                                     0                                0   \n",
       "2                                     0                                0   \n",
       "3                                     0                                0   \n",
       "4                                     0                                0   \n",
       "\n",
       "   roaster_location_Zhuwei, Taiwan  roaster_location_Zimbabwe  \\\n",
       "0                                0                          0   \n",
       "1                                0                          0   \n",
       "2                                0                          0   \n",
       "3                                0                          0   \n",
       "4                                0                          0   \n",
       "\n",
       "   roaster_location_Zurich, Switzerland    rating  \n",
       "0                                     0  0.517301  \n",
       "1                                     0  0.274650  \n",
       "2                                     0  0.759951  \n",
       "3                                     0  0.759951  \n",
       "4                                     0  0.517301  \n",
       "\n",
       "[5 rows x 4174 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Removes deprecation warnings\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns # For all our visualization needs.\n",
    "from pandas_profiling import ProfileReport # Creates data description, visuals, and missing value statistics for the data frame\n",
    "from IPython.display import display\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the data and run a ProfileReport to find statistical descriptions, visuals, and missing value information\n",
    "df = pd.read_csv('reordered_preprocessed_coffee4.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801151c1-1eda-4d36-976e-05a48cafa203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train/test split data\n",
    "X = df.iloc[:, :-1]  # Features (all columns except the last one)\n",
    "y = df.iloc[:, -1]   # Target (last column)\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50fe0a82-3fc8-4457-b4d1-fe415ce91290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7037, 4174)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b755f08-b637-4afb-81bf-a46cc0343948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5629, 4173), (5629, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519a2262-0f67-4342-aae3-d1d492f34a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1408, 4173), (1408, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fe920c-370f-4575-8146-7e83cfb10b2b",
   "metadata": {},
   "source": [
    "# <u>Modeling</u>  \n",
    "Goal: Build 3 to 5 different models and identify the best one.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4aef4c-3fb0-44eb-bc73-f96b5760be4e",
   "metadata": {},
   "source": [
    "# Fit models with a training dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99af5a7-ef5a-42e2-8012-c44e5230d338",
   "metadata": {},
   "source": [
    "# Model 1: Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2f2998b-3068-4d01-a007-221419786e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model specific variables for the train/test set components\n",
    "XLR = X\n",
    "yLR = y\n",
    "X_trainLR = X_train\n",
    "X_testLR = X_test\n",
    "y_trainLR = y_train\n",
    "y_testLR = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084cb980-04a8-4746-8f56-5c39c1300b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create the model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "lr.fit(X_trainLR, y_trainLR)\n",
    "\n",
    "# Make predictions\n",
    "y_predLR = lr.predict(X_testLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74179d00-b256-4b67-8390-ef03b18fa966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for the Linear Regression Model: 446544337.98906857\n",
      "Mean Squared Error for the Linear Regression Model: 9.467784905330545e+19\n",
      "RMSE for the Linear Regression Model:  9730254315.962427\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# Calculate MAE\n",
    "maeLR = mean_absolute_error(y_testLR, y_predLR)\n",
    "\n",
    "# Print the MAE\n",
    "print(f\"Mean Absolute Error for the Linear Regression Model: {maeLR}\")\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for evaluation\n",
    "mseLR = mean_squared_error(y_testLR, y_predLR)\n",
    "print(f\"Mean Squared Error for the Linear Regression Model: {mseLR}\")\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmseLR = np.sqrt(mseLR)\n",
    "print(f\"RMSE for the Linear Regression Model: \", rmseLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2e97e-8877-47af-9478-2d60ad24b9df",
   "metadata": {},
   "source": [
    "# Model 2: Random Forest Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2a6b63-ec2c-41f8-83b8-5209a5efd570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model specific variables for the train/test set components\n",
    "XRF = X\n",
    "yRF = y\n",
    "X_trainRF = X_train\n",
    "X_testRF = X_test\n",
    "y_trainRF = y_train\n",
    "y_testRF = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f805a69d-106d-464a-9fce-ee12de786bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf.fit(X_trainRF, y_trainRF.values.ravel())  # Using .values.ravel() to convert y_train DataFrame to a 1D array\n",
    "\n",
    "# Predict on the test data\n",
    "y_predRF = rf.predict(X_testRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e0d68d-d04f-417b-ae34-af8364e2adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for the Random Forest Model: 0.1794049411585514\n",
      "Mean Squared Error for the Random Forest Regressor Model: 0.0832775065420507\n",
      "RMSE for the Random Forest Regressor Model:  0.28857842355597324\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAE\n",
    "maeRF= mean_absolute_error(y_testRF, y_predRF)\n",
    "\n",
    "# Print the MAE\n",
    "print(f\"Mean Absolute Error for the Random Forest Model: {maeRF}\")\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for evaluation\n",
    "mseRF = mean_squared_error(y_testRF, y_predRF)\n",
    "print(f\"Mean Squared Error for the Random Forest Regressor Model: {mseRF}\")\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmseRF = np.sqrt(mseRF)\n",
    "print(f\"RMSE for the Random Forest Regressor Model: \", rmseRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf05fd6e-caa9-45bb-86aa-9ea8f03403b9",
   "metadata": {},
   "source": [
    "# Model 3: Gradient Boosting Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1207e8a-88d1-4ea6-b134-35ff65014156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model specific variables for the train/test set components\n",
    "XGB = X\n",
    "yGB = y\n",
    "X_trainGB = X_train\n",
    "X_testGB = X_test\n",
    "y_trainGB = y_train\n",
    "y_testGB = y_test\n",
    "\n",
    "# Install XGBoost\n",
    "#! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af790e5-77cb-4307-b9f1-845a48f6a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "gb = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=10, seed=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gb.fit(X_trainGB, y_trainGB)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predGB = gb.predict(X_testGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7330c2d6-457b-435e-b039-e9f9bfa7d325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for the Extreme Gradient Boosting Model: 0.19203128125179927\n",
      "Mean Squared Error for the Extreme Gradient Boosting Model: 0.08294503229995759\n",
      "RMSE for the Extreme Gradient Boosting Model:  0.2880017921818501\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAE\n",
    "maeGB = mean_absolute_error(y_testGB, y_predGB)\n",
    "\n",
    "# Print the MAE\n",
    "print(f\"Mean Absolute Error for the Extreme Gradient Boosting Model: {maeGB}\")\n",
    "\n",
    "# Calculate Mean Squared Error for evaluation\n",
    "mseGB = mean_squared_error(y_testGB, y_predGB)\n",
    "print(f\"Mean Squared Error for the Extreme Gradient Boosting Model: {mseGB}\")\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmseGB = np.sqrt(mseGB)\n",
    "print(f\"RMSE for the Extreme Gradient Boosting Model: \", rmseGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c28bc-d11f-47d7-8f35-c87b5ae4ae5d",
   "metadata": {},
   "source": [
    "# Model 4: Support Vector Regression (SVR) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd80328b-9a97-4a58-b2a3-60320d424b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model specific variables for the train/test set components\n",
    "XSVR = X\n",
    "ySVR = y\n",
    "X_trainSVR = X_train\n",
    "X_testSVR = X_test\n",
    "y_trainSVR = y_train\n",
    "y_testSVR = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eff8084-7824-43da-a0c3-efb10c760dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Initialize the SVR model\n",
    "svr = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "svr.fit(X_trainSVR, y_trainSVR)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predSVR = svr.predict(X_testSVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16cc5632-b49d-4cda-aac9-bc0e2d95eeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for the Support Vector Regression Model: 0.18286007431960155\n",
      "Mean Squared Error for the Support Vector Regression Model: 0.08128681850700242\n",
      "RMSE for the Support Vecgtor Regression Model:  0.28510843289352633\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAE\n",
    "maeSVR= mean_absolute_error(y_testSVR, y_predSVR)\n",
    "\n",
    "# Print the MAE\n",
    "print(f\"Mean Absolute Error for the Support Vector Regression Model: {maeSVR}\")\n",
    "\n",
    "# Calculate Mean Squared Error for evaluation\n",
    "mseSVR = mean_squared_error(y_testSVR, y_predSVR)\n",
    "print(f\"Mean Squared Error for the Support Vector Regression Model: {mseSVR}\")\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmseSVR = np.sqrt(mseSVR)\n",
    "print(f\"RMSE for the Support Vecgtor Regression Model: \", rmseSVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ecda51-2829-4244-82bf-257d3cbde48f",
   "metadata": {},
   "source": [
    "# Model 5: Elastic Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c4e4a69-0381-4807-bc61-cde907627eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model specific variables for the train/test set components\n",
    "XEN = X\n",
    "yEN = y\n",
    "X_trainEN = X_train\n",
    "X_testEN = X_test\n",
    "y_trainEN = y_train\n",
    "y_testEN = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3882d481-a37c-4ea5-b8bd-9d24436cfc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Initialize the Elastic Net model\n",
    "en = ElasticNet(alpha=1.0, l1_ratio=0.5)  \n",
    "\n",
    "# Fit the model on the training data\n",
    "en.fit(X_trainEN, y_trainEN)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predEN = en.predict(X_testEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46e31f8c-f242-407e-b0e6-cffb3d8f3636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for the Elastic Net Model: 0.4807004765238523\n",
      "Mean Squared Error for the Elastic Net Model: 0.4763833374938104\n",
      "RMSE for the Elastic Net Model:  0.6902052864864268\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAE\n",
    "maeEN = mean_absolute_error(y_testEN, y_predEN)\n",
    "\n",
    "# Print the MAE\n",
    "print(f\"Mean Absolute Error for the Elastic Net Model: {maeEN}\")\n",
    "\n",
    "# Calculate Mean Squared Error for evaluation\n",
    "mseEN = mean_squared_error(y_testEN, y_predEN)\n",
    "print(f\"Mean Squared Error for the Elastic Net Model: {mseEN}\")\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmseEN = np.sqrt(mseEN)\n",
    "print(f\"RMSE for the Elastic Net Model: \", rmseEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be0ac4d-04ef-40fa-b856-b4ef44814367",
   "metadata": {},
   "source": [
    "# Review model outcomes — Iterate over additional models as needed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8c97ad7-919c-4345-8521-2f103c9ec992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model           MAE           MSE          RMSE\n",
      "0  Linear Regression  4.465443e+08  9.467785e+19  9.730254e+09\n",
      "1      Random Forest  1.794049e-01  8.327751e-02  2.885784e-01\n",
      "2         XGBoosting  1.920313e-01  8.294503e-02  2.880018e-01\n",
      "3        Elastic Net  4.807005e-01  4.763833e-01  6.902053e-01\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary containing your data\n",
    "table = {\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'XGBoosting', 'Elastic Net'],\n",
    "    'MAE': [maeLR, maeRF, maeGB, maeEN], \n",
    "    'MSE': [mseLR, mseRF, mseGB, mseEN],\n",
    "    'RMSE': [rmseLR, rmseRF, rmseGB, rmseEN]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "data_table = pd.DataFrame(table)\n",
    "\n",
    "# Display the data table\n",
    "print(data_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed66204-b741-4651-9db2-bb16da598720",
   "metadata": {},
   "source": [
    "# Identify the final model that you think is the best model for this project  \n",
    "Hint: the most powerful model isn’t always the best one to use. Other considerations\n",
    "include computational complexity, scalability, and maintenance costs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3efb75-e872-42bc-a325-85c55702fa7d",
   "metadata": {},
   "source": [
    "Extreme Gradient Boosting displays the lowest MSE and RMSE, and second lowest MAE. I will select the Extreme Gradient Boosting as the best model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
